import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from scipy.stats import pearsonr

# Only these columns will be used as dependent variables
TARGET_FIELDS = ['Quota', 'Enrollment', 'Quota Rate']

def trim_string(x):
    return x.strip()

def replace_dash(value):
    if '--' in value:
        return np.nan
    return value

def trim_and_replace(value):
    value = trim_string(value)
    value = replace_dash(value)
    return value

# Define the data types for the columns
data_types = {'Year': int, 'University': str, 'City': str, 'Faculty': str, 'Department': str, 'Language': str,
              'Quota': int, 'Enrollment': int, 'Base Score': float, 'Ceiling Score': float, 'Quota Rate': float, }

converter_dict = {column: trim_and_replace for column in data_types.keys()}

# Read the CSV file with specified data types
df = pd.read_csv('uniData.csv', converters=converter_dict)
df = df.astype(data_types)

# Create a dictionary to hold the LabelEncoders for each column
label_encoders = {}

# Iterate over each column of type 'object'
for column in df.select_dtypes(include=[object]).columns:
    # Create a new LabelEncoder for this column
    le = LabelEncoder()

    # Fit and transform the data and store it in the DataFrame
    df[column] = le.fit_transform(df[column])

    # Store the LabelEncoder in our dictionary
    label_encoders[column] = le

# Handle missing values
# Store the original number of rows
original_rows = df.shape[0]

# Drop the NaN values
df = df.dropna()

# Calculate the number of rows after dropping NaN values
new_rows = df.shape[0]

# Calculate the number of rows removed
rows_removed = original_rows - new_rows

# Calculate the percentage of rows removed
percentage_removed = (rows_removed / original_rows) * 100

# Print the results
print(f"Number of rows removed: {rows_removed}")
print(f"Percentage of rows removed: {percentage_removed}%")

# Split the data into features and targets
X = df.drop(TARGET_FIELDS, axis=1)
y = df[TARGET_FIELDS]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a multivariate regression model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error (MSE):", mse)
print("Mean Absolute Error (MAE):", mae)
print("R^2 Score:", r2)
print("Train Accuracy Rate:", model.score(X_train, y_train))
print("Test Accuracy Rate:", model.score(X_test, y_test))

# Calculate Pearson correlation coefficient for each target variable separately
pearson_corr = {}
for i, target_field in enumerate(TARGET_FIELDS):
    corr, _ = pearsonr(y_test[target_field], y_pred[:, i])
    pearson_corr[target_field] = corr

print("Pearson Correlation Coefficient:")
for target_field, corr in pearson_corr.items():
    print(f"{target_field}: {corr}")

# Prepare data for 2024 forecast
data_2024 = df[df['Year'] == 2023].copy()
data_2024['Year'] = 2024

# Predict enrollment rate for 2024
X_2024 = data_2024.drop(TARGET_FIELDS, axis=1)
y_2024_pred = model.predict(X_2024)

# Convert the numpy array to a DataFrame
y_2024_pred_df = pd.DataFrame(y_2024_pred, columns=['2024 Predicted Quota', '2024 Predicted Enrollment', '2024 Predicted Quota Rate'])

# Reset the index of data_2024 to match with y_2024_pred_df
data_2024.reset_index(drop=True, inplace=True)

# Concatenate the predicted values with the data_2024 DataFrame
data_2024 = pd.concat([data_2024, y_2024_pred_df], axis=1)

# Get the data for 2023
data_2023 = df[df['Year'] == 2023].copy()
data_2023 = data_2023[TARGET_FIELDS]

# Reset the index of data_2023 to match with data_2024
data_2023.reset_index(drop=True, inplace=True)

# Concatenate the 2023 data with the 2024 predicted data
data_2023_2024 = pd.concat([data_2024, data_2023.add_prefix('2023 ')], axis=1)

# Decode the encoded columns
for column, encoder in label_encoders.items():
    if column in data_2023_2024.columns:
        data_2023_2024[column] = encoder.inverse_transform(data_2023_2024[column])

# Define the desired column order
column_order = ['University', 'City', 'Faculty', 'Department', 'Language','Base Score','Ceiling Score', '2023 Quota Rate', '2024 Predicted Quota Rate',
                '2023 Quota', '2024 Predicted Quota', '2023 Enrollment', '2024 Predicted Enrollment']

# Reorder the DataFrame
data_2023_2024 = data_2023_2024[column_order]

# Save the DataFrame to a CSV file
data_2023_2024.round(2).to_csv('predicted_uni_data_randomforest2.csv', index=False)
